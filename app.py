# ===================================================================
# --- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (Import Libraries) ---
# ===================================================================
import serial
import serial.tools.list_ports
import cv2
import PySimpleGUI as sg
import pyautogui
import numpy as np
import keyboard
import time
from flask import Flask
from threading import Thread
import socket

# ===================================================================
# --- è¨­å®šé …ç›® (Initial Settings) ---
# ã“ã‚Œã‚‰ã®å€¤ã¯UIã‹ã‚‰å¤‰æ›´å¯èƒ½ã§ã™
# ===================================================================

# --- ã‚·ãƒªã‚¢ãƒ«é€šä¿¡è¨­å®š ---
SERIAL_PORT = 'COM12'
BAUD_RATE = 115200

# --- Webã‚µãƒ¼ãƒãƒ¼è¨­å®š ---
FLASK_PORT = 5000

# --- IMU (BNO055) è¨­å®š ---
SENSITIVITY_X = 5.0   # Xè»¸ï¼ˆæ°´å¹³æ–¹å‘ï¼‰ã®æ„Ÿåº¦
SENSITIVITY_Y = -10.0 # Yè»¸ï¼ˆå‚ç›´æ–¹å‘ï¼‰ã®æ„Ÿåº¦
DEAD_ZONE = 0.5       # IMUã®å‹•ãã‚’ç„¡è¦–ã™ã‚‹é–¾å€¤
DELTA_THRESH = 0.5    # ã‚«ãƒ¡ãƒ©ã®å‹•ãã‚’ã€Œã‚ãšã‹ã«å‹•ã„ã¦ã„ã‚‹ã€ã¨ã¿ãªã™é–¾å€¤
# --- ã‚«ãƒ¡ãƒ©è¨­å®š ---
BRIGHT_SPOT_THRESHOLD = 200 # è¿½è·¡å¯¾è±¡ã¨ã¿ãªã™è¼åº¦ã®é–¾å€¤
SAFETY_MARGIN_PERCENT = 0.1 # ã‚«ãƒ¡ãƒ©æ˜ åƒã®ç«¯ã‚’é™¤å¤–ã™ã‚‹å‰²åˆ

# --- ã‚»ãƒ³ã‚µãƒ¼ãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³è¨­å®š ---
ALPHA_NORMAL = 0.4      # é€šå¸¸æ™‚ã®ã‚«ãƒ¡ãƒ©è¿½å¾“åº¦
ALPHA_STATIONARY = 0.1  # é™æ­¢æ™‚ã®ãƒã‚¤ã‚ºæŠ‘åˆ¶å¼·åº¦

# --- UIãƒ»ãƒ‡ãƒãƒƒã‚°è¨­å®š ---
UI_ENABLED = True # Falseã«ã™ã‚‹ã¨GUIã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’è¡¨ç¤ºã—ã¾ã›ã‚“

# ===================================================================
# --- ãƒ—ãƒ­ã‚°ãƒ©ãƒ æœ¬ä½“ (ã“ã“ã‹ã‚‰ä¸‹ã¯åŸå‰‡ã¨ã—ã¦å¤‰æ›´ä¸è¦ã§ã™) ---
# ===================================================================

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ---
mouse_control_active = True
pyautogui.FAILSAFE = False
fused_screen_x, fused_screen_y = pyautogui.size()[0] / 2, pyautogui.size()[1] / 2
last_cam_x, last_cam_y = fused_screen_x, fused_screen_y

def find_serial_port():
    """åˆ©ç”¨å¯èƒ½ãªã‚·ãƒªã‚¢ãƒ«ãƒãƒ¼ãƒˆã‚’æ¢ã—ã¦Picoã¨æ€ã‚ã‚Œã‚‹ãƒãƒ¼ãƒˆã‚’è¿”ã™"""
    ports = serial.tools.list_ports.comports()
    if not ports:
        return None
    print("åˆ©ç”¨å¯èƒ½ãªã‚·ãƒªã‚¢ãƒ«ãƒãƒ¼ãƒˆ:")
    for port in ports:
        print(f"  - {port.device} ({port.description})")
    for port in ports:
        if 'pico' in port.description.lower() or 'usb serial' in port.description.lower():
            print(f"Picoã¨æ€ã‚ã‚Œã‚‹ãƒãƒ¼ãƒˆ '{port.device}' ã‚’é¸æŠã—ã¾ã—ãŸã€‚")
            return port.device
    if ports:
        print(f"PicoãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æœ€åˆã®ãƒãƒ¼ãƒˆ '{ports[0].device}' ã‚’é¸æŠã—ã¾ã™ã€‚")
        return ports[0].device
    return None

def get_ip_address():
    """ãƒ­ãƒ¼ã‚«ãƒ«IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—ã™ã‚‹"""
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
        s.close()
        return ip
    except Exception:
        return "127.0.0.1"

def toggle_mouse_control(event=None):
    """ãƒã‚¦ã‚¹åˆ¶å¾¡ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹"""
    global mouse_control_active
    mouse_control_active = not mouse_control_active
    status = 'å†é–‹' if mouse_control_active else 'ä¸€æ™‚åœæ­¢'
    print(f"\n[æ“ä½œ] ãƒã‚¦ã‚¹åˆ¶å¾¡ã‚’{status}ã—ã¾ã—ãŸã€‚(ESCã‚­ãƒ¼ã§åˆ‡ã‚Šæ›¿ãˆ)")

keyboard.on_press_key("esc", toggle_mouse_control)

def run_flask_app(ser_instance):
    """Webã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ã‚·ãƒªã‚¢ãƒ«é€šä¿¡ã‚’ä¸­ç¶™ã™ã‚‹"""
    app = Flask(__name__)
    @app.route('/send/<data>')
    def send_data(data):
        if ser_instance and ser_instance.is_open:
            if data in ['1', '2']:
                try:
                    ser_instance.write(data.encode('utf-8'))
                    print(f"ğŸ“¨ [Web] ãƒ‡ãƒã‚¤ã‚¹ã« '{data}' ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")
                    return f"<h1>'{data}' ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«é€ä¿¡ã—ã¾ã—ãŸ</h1>"
                except serial.SerialException as e:
                    return f"<h1>é€ä¿¡ã‚¨ãƒ©ãƒ¼</h1><p>{e}</p>", 500
            else:
                return "<h1>ç„¡åŠ¹ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã™</h1>", 400
        else:
            return "<h1>é€ä¿¡ã‚¨ãƒ©ãƒ¼</h1><p>ã‚µãƒ¼ãƒãƒ¼å´ã§ã‚·ãƒªã‚¢ãƒ«ãƒ‡ãƒã‚¤ã‚¹ãŒæ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚</p>", 503
    local_ip = get_ip_address()
    print("\n" + "="*50)
    print("ğŸš€ Webã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¾ã—ãŸã€‚")
    print(f"   URLã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã‚¯ãƒªãƒƒã‚¯æ“ä½œãŒã§ãã¾ã™:")
    print(f"   - http://{local_ip}:{FLASK_PORT}/send/1 (å·¦ã‚¯ãƒªãƒƒã‚¯ç›¸å½“)")
    print(f"   - http://{local_ip}:{FLASK_PORT}/send/2 (å³ã‚¯ãƒªãƒƒã‚¯ç›¸å½“)")
    print("="*50 + "\n")
    app.run(host='0.0.0.0', port=FLASK_PORT, debug=False, use_reloader=False)

def main():
    global fused_screen_x, fused_screen_y, last_cam_x, last_cam_y

    # --- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã«ã‚³ãƒ”ãƒ¼ ---
    p_sens_x = SENSITIVITY_X
    p_sens_y = SENSITIVITY_Y
    p_dead_zone = DEAD_ZONE
    p_bright_thresh = BRIGHT_SPOT_THRESHOLD
    p_alpha_normal = ALPHA_NORMAL
    p_alpha_stationary = ALPHA_STATIONARY
    delta_threshold = DELTA_THRESH
    noise_flag=False
    # --- Webã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ– ---
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        sg.popup_error("ã‚¨ãƒ©ãƒ¼: Webã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # --- ã‚·ãƒªã‚¢ãƒ«ãƒãƒ¼ãƒˆã®åˆæœŸåŒ– ---
    ser = None
    port_to_use = SERIAL_PORT
    if port_to_use.lower() == 'auto':
        port_to_use = find_serial_port()
    if port_to_use:
        try:
            ser = serial.Serial(port=port_to_use, baudrate=BAUD_RATE, timeout=0.1)
            print(f"âœ… IMUæ¥ç¶šæˆåŠŸ: '{port_to_use}' @ {BAUD_RATE} bps")
            time.sleep(2)
            ser.flushInput()
        except serial.SerialException as e:
            print(f"âš ï¸ è­¦å‘Š: IMUãƒãƒ¼ãƒˆ '{port_to_use}' ã‚’é–‹ã‘ã¾ã›ã‚“ã€‚ã‚«ãƒ¡ãƒ©ã®ã¿ã§å‹•ä½œã—ã¾ã™ã€‚\n   {e}")
            ser = None
    else:
        print("âš ï¸ è­¦å‘Š: IMUãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚«ãƒ¡ãƒ©ã®ã¿ã§å‹•ä½œã—ã¾ã™ã€‚")

    # --- Webã‚µãƒ¼ãƒãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹• ---
    flask_thread = Thread(target=run_flask_app, args=(ser,), daemon=True)
    flask_thread.start()

    # --- ç”»é¢ã¨ã‚«ãƒ¡ãƒ©ã®ã‚µã‚¤ã‚ºè¨­å®š ---
    cam_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    cam_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    CAM_X_MIN = cam_width * SAFETY_MARGIN_PERCENT
    CAM_X_MAX = cam_width * (1 - SAFETY_MARGIN_PERCENT)
    CAM_Y_MIN = cam_height * SAFETY_MARGIN_PERCENT
    CAM_Y_MAX = cam_height * (1 - SAFETY_MARGIN_PERCENT)
    SCREEN_WIDTH, SCREEN_HEIGHT = pyautogui.size()

    # --- GUIã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®åˆæœŸåŒ– ---
    window = None
    if UI_ENABLED:
        sg.theme('Black')
        
        # --- UIãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå®šç¾© ---
        video_column = [
            [sg.Text('çŠ¶æ…‹: èµ·å‹•ä¸­...', key='-STATUS-', size=(40, 1), justification='center', text_color='lightgreen')],
            [sg.Image(filename='', key='-IMAGE-')]
        ]

        param_column = [
            [sg.Checkbox('IMUã‚»ãƒ³ã‚µãƒ¼ã‚’åˆ©ç”¨ã™ã‚‹', default=False, key='-USE_IMU-', disabled=ser is None, enable_events=True)],
            [sg.Frame('IMUè¨­å®š', [
                [sg.Text('æ„Ÿåº¦ X', size=(10,1)), sg.Slider(range=(-100.0, 100.0), default_value=p_sens_x, resolution=0.1, orientation='h', key='-SENS_X-', enable_events=True, size=(20,15))],
                [sg.Text('æ„Ÿåº¦ Y', size=(10,1)), sg.Slider(range=(-100.0, 100.0), default_value=p_sens_y, resolution=0.1, orientation='h', key='-SENS_Y-', enable_events=True, size=(20,15))],
                [sg.Text('é™æ­¢é–¾å€¤', size=(10,1)), sg.Slider(range=(75.0, 80.0), default_value=p_dead_zone, resolution=0.1, orientation='h', key='-DEAD_ZONE-', enable_events=True, size=(20,15))]
            ], key='-IMU_FRAME-')],
            [sg.Frame('ã‚«ãƒ¡ãƒ©ãƒ»ãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³è¨­å®š', [
                [sg.Checkbox('ãƒã‚¤ã‚ºæŠ‘åˆ¶ãƒ¢ãƒ¼ãƒ‰', default=False, key='-USE_DELAY-', disabled=ser is None, enable_events=True)],
                [sg.Text('è¼åº¦ã—ãã„å€¤', size=(10,1)), sg.Slider(range=(50, 255), default_value=p_bright_thresh, resolution=1, orientation='h', key='-BRIGHT-', enable_events=True, size=(20,15))],
                [sg.Text('è¿½å¾“åº¦ï¼ˆã“ã“ã§ã‚¹ãƒ ãƒ¼ã‚ºã«å‹•ãã‹ã©ã†ã‹ãŒæ±ºã¾ã‚‹ï¼‰', size=(10,1)), sg.Slider(range=(0.1, 1.0), default_value=p_alpha_normal, resolution=0.05, orientation='h', key='-ALPHA_N-', enable_events=True, size=(20,15))],
                [sg.Text('ãƒã‚¤ã‚ºæŠ‘åˆ¶ï¼ˆå‹•ã‹ãªã„ã¨ãã®ãƒ–ãƒ¬ã‚’æŠ‘ãˆã‚‹ï¼‰', size=(10,1)), sg.Slider(range=(0.1, 0.5), default_value=p_alpha_stationary, resolution=0.01, orientation='h', key='-ALPHA_S-', enable_events=True, size=(20,15))],
                [sg.Text('ã‚«ãƒ¡ãƒ©å‹•ä½œé–¾å€¤', size=(10,1)), sg.Slider(range=(0, 10), default_value=delta_threshold, resolution=0.01, orientation='h', key='-CAM-', enable_events=True, size=(20,15))]
            ])],
            [sg.VPush()],
            [sg.Button('çµ‚äº†', size=(10, 1))]
        ]

        layout = [[sg.Column(video_column), sg.VSeperator(), sg.Column(param_column)]]
        window = sg.Window('Adaptive Sensor Fusion Mouse Tracker', layout, finalize=True)

    print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚ESCã‚­ãƒ¼ã§ãƒã‚¦ã‚¹åˆ¶å¾¡ã‚’ä¸€æ™‚åœæ­¢/å†é–‹ã§ãã¾ã™ã€‚")

    # --- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— ---
    try:
        while True:
            if UI_ENABLED:
                event, values = window.read(timeout=1)
                if event == 'çµ‚äº†' or event == sg.WIN_CLOSED:
                    break
                
                # --- UIã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–° ---
                p_sens_x = values['-SENS_X-']
                p_sens_y = values['-SENS_Y-']
                p_dead_zone = values['-DEAD_ZONE-']
                p_bright_thresh = values['-BRIGHT-']
                p_alpha_normal = values['-ALPHA_N-']
                p_alpha_stationary = values['-ALPHA_S-']
                use_imu = values['-USE_IMU-']
                noise_flag=values['-USE_DELAY-']
                delta_threshold=values['-CAM-']
                # IMUãŒç„¡åŠ¹ãªã‚‰é–¢é€£ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚‚ç„¡åŠ¹åŒ–
                window['-IMU_FRAME-'].update(visible=use_imu)

            else: # UIç„¡åŠ¹æ™‚ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°
                use_imu = ser is not None

            # --- 1. ã‚«ãƒ¡ãƒ©ãƒ‡ãƒ¼ã‚¿ã®å–å¾— ---
            ret, frame = cap.read()
            if not ret: break
            frame = cv2.flip(frame, 1)

            # --- 2. IMUãƒ‡ãƒ¼ã‚¿ã®å–å¾— ---
            delta_h, delta_p, is_imu_moving = 0.0, 0.0, False
            if ser and use_imu and ser.in_waiting > 0:
                try:
                    line = ser.readline().decode('utf-8', 'ignore').strip()
                    if line:
                        parts = line.split(',')
                        if len(parts) == 6:
                            delta_h, delta_p = float(parts[0]), float(parts[2])
                            if abs(delta_h) > p_dead_zone or abs(delta_p) > p_dead_zone:
                                is_imu_moving = True
                except (UnicodeDecodeError, ValueError, IndexError):
                    pass

            # --- 3. ã‚«ãƒ¡ãƒ©ç”»åƒå‡¦ç† ---
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            (_, maxVal, _, maxLoc) = cv2.minMaxLoc(gray)
            is_cam_tracking = maxVal >= p_bright_thresh
            
            camera_screen_x, camera_screen_y = last_cam_x, last_cam_y
            if is_cam_tracking:
                cam_x_raw, cam_y_raw = maxLoc
                camera_screen_x = np.interp(cam_x_raw, [CAM_X_MIN, CAM_X_MAX], [0, SCREEN_WIDTH - 1])
                camera_screen_y = np.interp(cam_y_raw, [CAM_Y_MIN, CAM_Y_MAX], [0, SCREEN_HEIGHT - 1])

            # --- 4. çŠ¶æ³åˆ¤æ–­ã¨ã‚»ãƒ³ã‚µãƒ¼ãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³ ---
            if mouse_control_active:
                if use_imu and ser: # --- ã‚»ãƒ³ã‚µãƒ¼ãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ ---
                    if not is_cam_tracking and is_imu_moving:
                        status_text, status_color = "çŠ¶æ…‹: IMUäºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰", "magenta"
                        fused_screen_x += delta_h * p_sens_x
                        fused_screen_y += delta_p * p_sens_y
                        cv2.putText(frame, "IMU PREDICTION", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,255), 2)
                    elif is_cam_tracking:
                        cam_delta = np.sqrt((camera_screen_x - last_cam_x)**2 + (camera_screen_y - last_cam_y)**2)
                        is_cam_moving_slightly = cam_delta > delta_threshold
                        if not is_imu_moving and is_cam_moving_slightly:
                            status_text, status_color = "çŠ¶æ…‹: ãƒã‚¤ã‚ºæŠ‘åˆ¶ãƒ¢ãƒ¼ãƒ‰", "orange"
                            alpha = p_alpha_stationary
                            cv2.circle(frame, maxLoc, 20, (0, 165, 255), 2)
                        else:
                            status_text, status_color = "çŠ¶æ…‹: é€šå¸¸è¿½è·¡ãƒ¢ãƒ¼ãƒ‰", "cyan"
                            alpha = p_alpha_normal
                            cv2.circle(frame, maxLoc, 20, (255, 255, 0), 2)
                        fused_screen_x = (1 - alpha) * fused_screen_x + alpha * camera_screen_x
                        fused_screen_y = (1 - alpha) * fused_screen_y + alpha * camera_screen_y
                    else:
                        status_text, status_color = "çŠ¶æ…‹: è¿½è·¡å¯¾è±¡ãªã—", "red"
                
                else: # --- ã‚«ãƒ¡ãƒ©å˜ç‹¬ãƒ¢ãƒ¼ãƒ‰ ---
                    if is_cam_tracking:
                        cam_delta = np.sqrt((camera_screen_x - last_cam_x)**2 + (camera_screen_y - last_cam_y)**2)
                        is_cam_moving_slightly = cam_delta > delta_threshold
                        if noise_flag:
                            status_text, status_color = "çŠ¶æ…‹: å˜ç‹¬ãƒã‚¤ã‚ºæŠ‘åˆ¶ãƒ¢ãƒ¼ãƒ‰", "orange"
                            alpha = p_alpha_stationary
                            
                        else:
                            status_text, status_color = "çŠ¶æ…‹: ã‚«ãƒ¡ãƒ©å˜ç‹¬ãƒ¢ãƒ¼ãƒ‰", "lime"
                            alpha = p_alpha_normal
                        fused_screen_x = (1 - alpha) * fused_screen_x + alpha * camera_screen_x
                        fused_screen_y = (1 - alpha) * fused_screen_y + alpha * camera_screen_y
                        cv2.circle(frame, maxLoc, 20, (0, 255, 0), 2)
                    

                    else:
                        status_text, status_color = "çŠ¶æ…‹: è¿½è·¡å¯¾è±¡ãªã—", "red"
            else:
                status_text, status_color = "çŠ¶æ…‹: ä¸€æ™‚åœæ­¢ä¸­ (ESCã‚­ãƒ¼ã§å†é–‹)", "yellow"

            # --- 5. ãƒã‚¦ã‚¹ç§»å‹• & UIæ›´æ–° ---
            if mouse_control_active:
                final_x = np.clip(fused_screen_x, 0, SCREEN_WIDTH - 1)
                final_y = np.clip(fused_screen_y, 0, SCREEN_HEIGHT - 1)
                pyautogui.moveTo(final_x, final_y)

            if UI_ENABLED:
                window['-STATUS-'].update(status_text, text_color=status_color)
                display_frame = cv2.resize(frame, (640, 480))
                imgbytes = cv2.imencode('.png', display_frame)[1].tobytes()
                window['-IMAGE-'].update(data=imgbytes)
            
            last_cam_x, last_cam_y = camera_screen_x, camera_screen_y

    finally:
        print("\nã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...")
        cap.release()
        if ser and ser.is_open: ser.close(); print("ã‚·ãƒªã‚¢ãƒ«ãƒãƒ¼ãƒˆã‚’é–‰ã˜ã¾ã—ãŸã€‚")
        if UI_ENABLED and window: window.close()
        keyboard.unhook_all()
        print("çµ‚äº†ã—ã¾ã—ãŸã€‚")

if __name__ == '__main__':
    main()

